{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import *\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "# my defined module\n",
    "from fr_utils import image_loader, EmbeddingNet, TripletLoss, BinaryLoss, TripletNet\n",
    "from fr_utils import img_encoding, verification, recognition\n",
    "from inception_resnet_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'dataset/bertrand.jpg'\n",
    "y = 'dataset/bertrand_2.jpg'\n",
    "z = 'dataset/train/arnaud/arnaud.jpg'\n",
    "j = 'dataset/danielle.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 96\n",
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                     [0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(y); img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor, positive, negative = image_loader(x, transform=transform), image_loader(y, transform), image_loader(z, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anchor.size())\n",
    "in_layer = anchor.shape[1] * anchor.shape[2] * 2\n",
    "in_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = InceptionResnetV1(pretrained='vggface2', classify=True).eval().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed.logits = nn.Linear(512, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_x, embedded_y, embedded_z = embed(anchor), embed(positive), embed(negative) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = TripletLoss()\n",
    "l = loss.forward(embedded_x, embedded_y, embedded_z); l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_positive = F.pairwise_distance(embedded_x, embedded_y).pow(2).sum(); distance_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_encoding(\"dataset/danielle.jpg\", transform, embed)\n",
    "database[\"younes\"] = img_encoding(\"dataset/younes.jpg\", transform, embed)\n",
    "database[\"tian\"] = img_encoding(\"dataset/tian.jpg\", transform, embed)\n",
    "database[\"andrew\"] = img_encoding(\"dataset/andrew.jpg\", transform, embed)\n",
    "database[\"kian\"] = img_encoding(\"dataset/kian.jpg\", transform, embed)\n",
    "database[\"dan\"] = img_encoding(\"dataset/dan.jpg\", transform, embed)\n",
    "database[\"sebastiano\"] = img_encoding(\"dataset/sebastiano.jpg\", transform, embed)\n",
    "database[\"bertrand\"] = img_encoding(\"dataset/bertrand.jpg\", transform, embed)\n",
    "database[\"kevin\"] = img_encoding(\"dataset/kevin.jpg\", transform, embed)\n",
    "database[\"felix\"] = img_encoding(\"dataset/felix.jpg\", transform, embed)\n",
    "database[\"benoit\"] = img_encoding(\"dataset/benoit.jpg\", transform, embed)\n",
    "database[\"arnaud\"] = img_encoding(\"dataset/arnaud.jpg\", transform, embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification(image_path, identity, db, embednet, transform=None)\n",
    "\n",
    "verification(\"dataset/danielle.jpg\", 'dan', database, embed, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition(\"dataset/dan_2.jpg\", database, embed, transform=transform, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
